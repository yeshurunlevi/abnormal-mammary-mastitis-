{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9265ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SELF-CONTAINED SECOND PANE: Heatmaps + CSV summary from existing patch RMSEs ===\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = 128\n",
    "PATCH_STRIDE = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "TEST_FOLDER = r\"C:\\Users\\shpigel-lab\\Desktop\\tiles\\test\"\n",
    "MODEL_PATH = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\models\\autoencoder.pth\"\n",
    "OUTPUT_CSV = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\test_anomalies.csv\"\n",
    "HEATMAP_DIR = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\test_heatmaps\"\n",
    "os.makedirs(HEATMAP_DIR, exist_ok=True)\n",
    "\n",
    "# === TRANSFORM ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# === MODEL ===\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, 1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, 2, 1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 3, 2, 1, output_padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "model = Autoencoder().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Re-run inference just to get patch scores again ===\n",
    "def process_group(folder):\n",
    "    result = {}\n",
    "    files = glob.glob(os.path.join(folder, \"*.png\"))\n",
    "    batch = []\n",
    "    coords = []\n",
    "\n",
    "    for f in tqdm(files, desc=\"ðŸ”„ Loading & scoring test patches\"):\n",
    "        fname = os.path.basename(f)\n",
    "        slide = fname.split(\"_\")[0]\n",
    "        x, y = int(fname.split(\"_\")[1]), int(fname.split(\"_\")[2].split(\".\")[0])\n",
    "        try:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "        except:\n",
    "            continue\n",
    "        tensor = transform(img)\n",
    "        batch.append(tensor)\n",
    "        coords.append((slide, x, y))\n",
    "\n",
    "        if len(batch) == BATCH_SIZE:\n",
    "            batch_tensor = torch.stack(batch).to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                recon = model(batch_tensor)\n",
    "                rmse = torch.sqrt(torch.mean((batch_tensor - recon) ** 2, dim=(1, 2, 3))).cpu().numpy()\n",
    "            for (sid, x, y), score in zip(coords, rmse):\n",
    "                result.setdefault(sid, []).append((x, y, score))\n",
    "            batch, coords = [], []\n",
    "\n",
    "    if batch:\n",
    "        batch_tensor = torch.stack(batch).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            recon = model(batch_tensor)\n",
    "            rmse = torch.sqrt(torch.mean((batch_tensor - recon) ** 2, dim=(1, 2, 3))).cpu().numpy()\n",
    "        for (sid, x, y), score in zip(coords, rmse):\n",
    "            result.setdefault(sid, []).append((x, y, score))\n",
    "\n",
    "    return result\n",
    "\n",
    "results = process_group(TEST_FOLDER)\n",
    "np.save(r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\test_patch_scores.npy\", results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882c3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# === CONFIG ===\n",
    "PATCH_STRIDE = 256\n",
    "HEATMAP_DIR = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\test_heatmaps\"\n",
    "OUTPUT_CSV = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\test_anomalies.csv\"\n",
    "os.makedirs(HEATMAP_DIR, exist_ok=True)\n",
    "\n",
    "# === LOAD RESULTS ===\n",
    "results = np.load(r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\test_patch_scores.npy\", allow_pickle=True).item()\n",
    "\n",
    "# === GENERATE HEATMAPS + CSV ===\n",
    "rows = []\n",
    "for sid, patches in results.items():\n",
    "    try:\n",
    "        xs, ys, scores = zip(*patches)\n",
    "    except ValueError:\n",
    "        print(f\"âš ï¸ Skipping scan {sid}: no valid patches.\")\n",
    "        continue\n",
    "\n",
    "    mean_score = np.mean(scores)\n",
    "    rows.append({\"Scan\": sid, \"Anomaly\": mean_score})\n",
    "\n",
    "    # Build color heatmap\n",
    "    grid_w = (max(xs) // PATCH_STRIDE) + 1\n",
    "    grid_h = (max(ys) // PATCH_STRIDE) + 1\n",
    "    grid = np.zeros((grid_h, grid_w, 3), dtype=np.uint8)\n",
    "    norm_scores = [(s - min(scores)) / (max(scores) - min(scores) + 1e-8) for s in scores]\n",
    "\n",
    "    for (x, y, s) in zip(xs, ys, norm_scores):\n",
    "        i, j = y // PATCH_STRIDE, x // PATCH_STRIDE\n",
    "        color = (np.array(plt.cm.jet(s)[:3]) * 255).astype(np.uint8)\n",
    "        grid[i, j] = color\n",
    "\n",
    "    # Save heatmap\n",
    "    heatmap = cv2.resize(grid, (grid_w * 10, grid_h * 10), interpolation=cv2.INTER_NEAREST)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(heatmap)\n",
    "    ax.set_title(f\"{sid} heatmap\")\n",
    "    ax.axis('off')\n",
    "    sm = plt.cm.ScalarMappable(cmap='jet', norm=plt.Normalize(vmin=min(scores), vmax=max(scores)))\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, ax=ax, fraction=0.04, pad=0.05)\n",
    "    out_path = os.path.join(HEATMAP_DIR, f\"{sid}_heatmap.png\")\n",
    "    plt.savefig(out_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"âœ… Saved heatmap: {sid} -> {out_path}\")\n",
    "\n",
    "# Save CSV\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"ðŸ“Š Done! CSV saved to: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af501f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# === DEVICE & TRANSFORM ===\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "INPUT_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# === Autoencoder Model (same as before) ===\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, 1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, 2, 1, output_padding=1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 3, 2, 1, output_padding=1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# === Load model ===\n",
    "MODEL_PATH = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\models\\autoencoder.pth\"\n",
    "model = Autoencoder().to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Patch Scoring Function ===\n",
    "def compute_patch_scores(folder):\n",
    "    results = []\n",
    "    files = glob.glob(os.path.join(folder, \"*.png\"))\n",
    "    batch = []\n",
    "    coords = []\n",
    "\n",
    "    for f in tqdm(files, desc=f\"Scoring {os.path.basename(folder)}\"):\n",
    "        fname = os.path.basename(f)\n",
    "        slide = fname.split(\"_\")[0]\n",
    "        x, y = int(fname.split(\"_\")[1]), int(fname.split(\"_\")[2].split(\".\")[0])\n",
    "        try:\n",
    "            img = Image.open(f).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to open {f}: {e}\")\n",
    "            continue\n",
    "        tensor = transform(img)\n",
    "        batch.append(tensor)\n",
    "        coords.append((slide, x, y))\n",
    "\n",
    "        if len(batch) == BATCH_SIZE:\n",
    "            batch_tensor = torch.stack(batch).to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                recon = model(batch_tensor)\n",
    "                rmse = torch.sqrt(torch.mean((batch_tensor - recon) ** 2, dim=(1, 2, 3))).cpu().numpy()\n",
    "            for (slide_id, x, y), s in zip(coords, rmse):\n",
    "                results.append((slide_id, x, y, s))\n",
    "            batch = []\n",
    "            coords = []\n",
    "\n",
    "    # remaining\n",
    "    if batch:\n",
    "        batch_tensor = torch.stack(batch).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            recon = model(batch_tensor)\n",
    "            rmse = torch.sqrt(torch.mean((batch_tensor - recon) ** 2, dim=(1, 2, 3))).cpu().numpy()\n",
    "        for (slide_id, x, y), s in zip(coords, rmse):\n",
    "            results.append((slide_id, x, y, s))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3be1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_PATH = r\"C:\\Users\\shpigel-lab\\Documents\\DL project\\baseline_test_rmse.txt\"\n",
    "six_folder = \"C:\\\\Users\\\\shpigel-lab\\\\Desktop\\\\tiles\\\\twenty_four\"\n",
    "output_csv = \"C:\\\\Users\\\\shpigel-lab\\\\Documents\\\\DL project\\\\twenty_four_anomalies.csv\"\n",
    "heatmap_dir = \"C:\\\\Users\\\\shpigel-lab\\\\Documents\\\\DL project\\\\twenty_four_heatmaps\"\n",
    "os.makedirs(heatmap_dir, exist_ok=True)\n",
    "\n",
    "with open(BASELINE_PATH, \"r\") as f:\n",
    "    baseline = float(f.read().strip())\n",
    "\n",
    "results = compute_patch_scores(six_folder)\n",
    "df = pd.DataFrame(results, columns=[\"Slide\", \"X\", \"Y\", \"RMSE\"])\n",
    "df[\"Norm_RMSE\"] = df[\"RMSE\"] / baseline\n",
    "df[\"Abnormal\"] = df[\"Norm_RMSE\"] > 1.0\n",
    "\n",
    "# Save per-slide percentage summary\n",
    "summary = df.groupby(\"Slide\")[\"Abnormal\"].mean().reset_index()\n",
    "summary.rename(columns={\"Abnormal\": \"Abnormal_Pct\"}, inplace=True)\n",
    "summary.to_csv(output_csv, index=False)\n",
    "print(f\"âœ… CSV saved: {output_csv}\")\n",
    "\n",
    "# === Generate HEATMAPS per slide ===\n",
    "stride = 256\n",
    "for slide_id, group_df in df.groupby(\"Slide\"):\n",
    "    xs = group_df[\"X\"].values\n",
    "    ys = group_df[\"Y\"].values\n",
    "    scores = group_df[\"Norm_RMSE\"].values\n",
    "    grid_w = (max(xs) // stride) + 1\n",
    "    grid_h = (max(ys) // stride) + 1\n",
    "\n",
    "    grid = np.zeros((grid_h, grid_w, 3), dtype=np.uint8)\n",
    "    norm_scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores) + 1e-8)\n",
    "\n",
    "    for x, y, s in zip(xs, ys, norm_scores):\n",
    "        i, j = y // stride, x // stride\n",
    "        color = (np.array(plt.cm.jet(s)[:3]) * 255).astype(np.uint8)\n",
    "        grid[i, j] = color\n",
    "\n",
    "    heatmap = cv2.resize(grid, (grid_w * 10, grid_h * 10), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.imshow(heatmap)\n",
    "    ax.set_title(f\"{slide_id} Heatmap (Normalized)\")\n",
    "    ax.axis('off')\n",
    "    sm = plt.cm.ScalarMappable(cmap='jet', norm=plt.Normalize(vmin=np.min(scores), vmax=np.max(scores)))\n",
    "    sm.set_array([])\n",
    "    fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.savefig(os.path.join(heatmap_dir, f\"{slide_id}_heatmap.png\"), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"âœ… Heatmaps saved to: {heatmap_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
